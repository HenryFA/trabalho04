#Pedro Henrique Faria Amadeu

#Sua  tarefa  será  transformar  um  conjunto  de  5  sites,  sobre  o  tema  de  processamento  de 
#linguagem natural em um conjunto de cinco listas distintas de sentenças. Ou seja, você fará uma função 
#que, usando a biblioteca Beautifull Soap, faça a requisição de uma url, e extrai todas as sentenças desta url. Duas condições são importantes:  

#a) A página web (url) deve apontar para uma página web em inglês contendo, não menos que 1000 palavras.

#b) O texto desta página deverá ser transformado em um array de senteças.

#importando biblioteca necessaria
import requests
from bs4 import BeautifulSoup

#primeira url
url = requests.get('https://en.wikipedia.org/wiki/Natural_language_processing')

content = url.content

page = BeautifulSoup(content, 'html.parser')

resultado1 = []

text = page.find('div', attrs={'class': 'mw-parser-output'})

resultado1 = text.text


print (resultado1.split())
print ("total de palavras:", len(resultado1))

##############################################

#segunda url
url = requests.get('https://www.ibm.com/cloud/learn/natural-language-processing')

content = url.content

page = BeautifulSoup(content, 'html.parser')

resultado2 = []

text = page.find('div', attrs={'class': 'ibm-carbon-lh__container__second'})

resultado2 = text.text

print (resultado2.split())
print ("total de palavras:",len(resultado2))

##############################################

#terceira url
url = requests.get('https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP')

content = url.content

page = BeautifulSoup(content, 'html.parser')

resultado3 = []

text = page.find('article', attrs={'id': 'content-columns'})

resultado3 = text.text

print (resultado3.split())
print ("total de palavras:",len(resultado3))

############################################

#quarta url
url = requests.get('https://www.coursera.org/specializations/natural-language-processing')

content = url.content

page = BeautifulSoup(content, 'html.parser')

resultado4 = []

text = page.find('div', attrs={'class': '_1jug6qr SDPPage'})

resultado4 = text.text

print (resultado4.split())
print ("total de palavras:",len(resultado4))

############################################

#quinta url
url = requests.get('https://www.datarobot.com/blog/what-is-natural-language-processing-introduction-to-nlp/')

content = url.content

page = BeautifulSoup(content, 'html.parser')

resultado5 = []

text = page.find('div', attrs={'class': 'uk-grid uk-grid-large'})

resultado5 = text.text

print (resultado5.split())
print ("total de palavras:",len(resultado5))
